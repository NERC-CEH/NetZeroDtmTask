{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTM generation varying all parameters in a set\n",
    "--------------------------------------------------------------\n",
    "\n",
    "The dataset is chosen from the 'DUI' dataset as collected during the Paraguas. \n",
    "\n",
    "The pointcloud format is the .las one as commonly used. The data should look something like the below viewed in cloud compare (https://www.cloudcompare.org/).\n",
    "\n",
    "<img src=\"pics/incld.png\" style=\"height:300px\">\n",
    "\n",
    "This is variable terrain wise with plenty espis, so should be a good test as a flat area would not be very informative. \n",
    "\n",
    "The function is within and reliant on the pointutils library I author found here https://github.com/Ciaran1981/pointutils.\n",
    "Follow the instructions to install.\n",
    "\n",
    "The pointcloud is found in the 'data' directory in this repo. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointutils import utils as ut\n",
    "import os\n",
    "import zipfile\n",
    "from glob2 import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using os as you may be afflicted by windows ;D\n",
    "\n",
    "inzip = os.path.join('data', 'DUI_out_1.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(inzip, 'r') as zippy:\n",
    "    zippy.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incld = inzip[:-3]+'las'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function just uses sklearn's paramgrid to make a generator. As per the conventions of that lib, the params are a dict as follows:\n",
    "\n",
    "```python\n",
    "params={'scalar': [1,10], 'slope':[0.25,1], 'thresh':[0.1, 1], 'wind':[5, 20]}\n",
    "```\n",
    "How many is up to you, just put them in the lists. An explanation of them.\n",
    "\n",
    "- scalar: float\n",
    "          elevation scaling factor \n",
    "\n",
    "- slope: float\n",
    "         slope thresh (percent) \n",
    "\n",
    "- threshold: float\n",
    "         elevation threshold \n",
    "\n",
    "- window: int\n",
    "         max window size \n",
    "         \n",
    "Further info here https://pdal.io/stages/filters.smrf.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'scalar': [1,10], 'slope':[0.25,1], 'thresh':[0.1, 1], 'wind':[5, 20]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the line below took around 25 seconds on my computer (not parallelised). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.iter_smrf(incld, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output clouds are all named according to the input parameters.You can view the results in cloud compare, setting the **Colors** and **Scalar Fields>Count** as seen in the pic in the left-hand  **Properties** pane. \n",
    "\n",
    "<img src=\"pics/result.png\" style=\"height:500px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly hadn't thought this through,move the original cloud somewhere else!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('orig')\n",
    "shutil.move(incld, 'orig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What planar resolution this should be gridded to is another question. I have put this in here as 5cm, but it could be anything really. The interp is IDW. Up to you - or use your own method....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of files may be handy\n",
    "outfiles = glob(os.path.join('data', '*.las'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grid whole lot with this function in parallel.**\n",
    "\n",
    "Bare in mind datatype will affect the height results but make the files bigger/smaller.\n",
    "\n",
    "I have left as \"uint16_t\", but \"float32\" may be better\n",
    "\n",
    "nt = no of jobs....6 seconds on my computer with 16 files.....\n",
    "\n",
    "Below (counterintuitively) denotes we only grid ground points, with 1:1 denoting the non-ground.\n",
    "\n",
    "```python\n",
    "rng_limit=\"Classification[2:2]\"\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.grid_cloud_batch('data', attribute=\"z\", reader=\"readers.las\", \n",
    "                    writer=\"writers.gdal\", spref=\"EPSG:21818\", \n",
    "                    dtype=\"uint16_t\", outtype='idw', resolution=0.05, nt=-1, rng_limit=\"Classification[2:2]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pointutils]",
   "language": "python",
   "name": "conda-env-pointutils-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
